# Agno Agente de Pre√ßo de A√ß√µes

Um pequeno servi√ßo **FastAPI** que utiliza o framework **Agno** com um modelo **Ollama** para buscar pre√ßos de a√ß√µes via a ferramenta `YFinanceTools`.

---

## Pr√©‚Äërequisitos

- **Docker** e **Docker Compose** instalados na sua m√°quina.
- Um servidor **Ollama** rodando localmente (endere√ßo padr√£o `http://host.docker.internal:11434`).
- Uma chave de API da **OpenAI** (necess√°ria pelo pacote Agno mesmo ao usar Ollama).

## Configura√ß√£o

1. **Clone o reposit√≥rio**
   ```bash
   git clone https://github.com/fsmalaquias/estudo-agno-ai.git
   cd estudo-agno-ai
   ```

2. **Crie o arquivo `.env`** (j√° presente no reposit√≥rio) com as vari√°veis necess√°rias:
   ```dotenv
   OPENAI_API_KEY=sua‚Äëchave‚Äëopenai
   OLLAMA_HOST=http://host.docker.internal:11434
   ```
   *O arquivo `.env` est√° inclu√≠do no `.gitignore` e n√£o ser√° versionado.*

3. **Construa e inicie os containers**
   ```bash
   docker compose up -d --build
   ```
   O servi√ßo ficar√° dispon√≠vel em **http://localhost:8000**. O container executa o `uvicorn` com a flag `--reload`, portanto qualquer altera√ß√£o no c√≥digo fonte ser√° recarregada automaticamente.

## Uso da API

O servi√ßo exp√µe um √∫nico endpoint:

- **POST** `/query`
  - **Corpo da requisi√ß√£o** (JSON): `{ "question": "<sua pergunta>" }`
  - **Resposta** (JSON): `{ "answer": "<resultado>" }`

### Exemplo de requisi√ß√£o com `curl`
```bash
curl -X POST http://localhost:8000/query \
     -H "Content-Type: application/json" \
     -d '{"question":"Qual o pre√ßo da a√ß√£o da Apple?"}'
```

A resposta ser√° um JSON limpo, por exemplo:
```json
{ "answer": "229.35" }
```

Se o modelo LLM retornar um objeto de erro, a API encaminhar√° o c√≥digo de status HTTP e a mensagem apropriados.

---

## Notas de desenvolvimento

- O modelo LLM est√° configurado em `api.py` usando `Ollama(id="llama3.2")`. Altere o ID do modelo caso queira usar outro modelo Ollama.
- A fun√ß√£o auxiliar `clean_answer` remove fences de markdown, crases e quebras de linha antes de analisar a resposta.
- As vari√°veis de ambiente s√£o carregadas a partir do arquivo `.env` via Docker Compose (`env_file:`). Nenhum segredo est√° hard‚Äëcoded no Dockerfile.

Divirta‚Äëse desenvolvendo com **Agno**! üöÄ
